{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8577673,"sourceType":"datasetVersion","datasetId":5129481}],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sacremoses","metadata":{"_uuid":"389fa733-1231-4a8d-9e64-8f12fff841fd","_cell_guid":"f4a0c896-fb5c-4e15-9ddf-7334b5686b52","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-01T20:08:41.091669Z","iopub.execute_input":"2024-06-01T20:08:41.092012Z","iopub.status.idle":"2024-06-01T20:08:54.855668Z","shell.execute_reply.started":"2024-06-01T20:08:41.091984Z","shell.execute_reply":"2024-06-01T20:08:54.854583Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting sacremoses\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacremoses) (2023.12.25)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses) (1.4.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sacremoses) (4.66.4)\nDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: sacremoses\nSuccessfully installed sacremoses-0.1.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ntrans_df = pd.read_csv('/kaggle/input/kaz-rus-parallel-corpus/kazakh_russian_parallel_corpus.csv')","metadata":{"_uuid":"76e7957e-346d-47e2-a713-71f6370dfdad","_cell_guid":"34011332-7934-4fdd-87ab-17bbd685584f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-01T20:08:54.858079Z","iopub.execute_input":"2024-06-01T20:08:54.858838Z","iopub.status.idle":"2024-06-01T20:08:55.620930Z","shell.execute_reply.started":"2024-06-01T20:08:54.858789Z","shell.execute_reply":"2024-06-01T20:08:55.620146Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"_uuid":"8039088b-49c4-4873-9952-46285a8b68e6","_cell_guid":"099b1dbf-aa47-4095-a13e-9cb3f0bd54aa","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-01T20:08:55.625344Z","iopub.execute_input":"2024-06-01T20:08:55.625605Z","iopub.status.idle":"2024-06-01T20:08:55.899543Z","shell.execute_reply.started":"2024-06-01T20:08:55.625581Z","shell.execute_reply":"2024-06-01T20:08:55.898671Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f98c740851774e55b620457e32a9fa54"}},"metadata":{}}]},{"cell_type":"code","source":"pd.options.display.max_colwidth = 100","metadata":{"_uuid":"33eebc3e-db10-4510-803b-874f6ff6b054","_cell_guid":"6bd434b9-ac41-4903-ae23-cbb529c44350","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-01T20:09:15.755909Z","iopub.execute_input":"2024-06-01T20:09:15.756916Z","iopub.status.idle":"2024-06-01T20:09:15.761152Z","shell.execute_reply.started":"2024-06-01T20:09:15.756880Z","shell.execute_reply":"2024-06-01T20:09:15.760015Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Calculate lengths of the text in each column\nkazakh_lengths = trans_df['Kazakh'].str.len()\nsource_lengths = trans_df['Source'].str.len()\n\n# Apply the filtering condition\ntrans_df = trans_df[(source_lengths > kazakh_lengths * 0.7) & (source_lengths < kazakh_lengths * 1.3)]\n\ntrans_df = trans_df.drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T20:09:17.122464Z","iopub.execute_input":"2024-06-01T20:09:17.122819Z","iopub.status.idle":"2024-06-01T20:09:17.263067Z","shell.execute_reply.started":"2024-06-01T20:09:17.122783Z","shell.execute_reply":"2024-06-01T20:09:17.262277Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(trans_df.shape)\nprint(trans_df.columns)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T20:09:17.660601Z","iopub.execute_input":"2024-06-01T20:09:17.661407Z","iopub.status.idle":"2024-06-01T20:09:17.666186Z","shell.execute_reply.started":"2024-06-01T20:09:17.661376Z","shell.execute_reply":"2024-06-01T20:09:17.665193Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(32691, 2)\nIndex(['Source', 'Kazakh'], dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"trans_df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T20:09:18.009722Z","iopub.execute_input":"2024-06-01T20:09:18.010724Z","iopub.status.idle":"2024-06-01T20:09:18.027943Z","shell.execute_reply.started":"2024-06-01T20:09:18.010688Z","shell.execute_reply":"2024-06-01T20:09:18.026994Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                                                                    Source  \\\n28399                                                                   Мы более в нем не нуждаемся, мама.   \n12921                    Через несколько дней Хосе Аркадио Буэндия подыскал дом для семейства коррехидора.   \n7802                                                                      Человек долго смотрел на Джоуда.   \n4204   Легко себе представить, что странные повадки Динго не раз служили темой бесед, которые вели на к...   \n33010                                                                 — Все исправно, — сказал англичанин.   \n21581                             Сколько мы плыли по реке, сколько делали для этих мошенников, и все зря!   \n15683                                                           Я от него ничего не видела, кроме добра...   \n5911            — Друзья мои, — сказал он вполголоса, как будто разговаривая сам с собой, — слушайте меня.   \n17979                                          Спектакль был не такой дрянной, как те, что я раньше видел.   \n17522  Две вещи здесь как-то странно останавливали внимание: небольшой погнутый самовар, стоявший на по...   \n\n                                                                                                    Kazakh  \n28399                                                                     − Ол енді бізге керек емес, апа.  \n12921                   Бірнеше күн өткен соң, Хосе Аркадио Буэндиа коррехидордың отбасына үй тауып берді.  \n7802                                                                          Oл адам Джoудқа ұзақ қарады.  \n4204   Дингоның адам таңқаларлық қылығы капитан Гульдің, миссис Уэлдонның және Диктің кеме кормосындағы...  \n33010                                                                  — Бәз бабында бәрі, — деді ағылшын.  \n21581                         Біз өзенмен қанша жол жүрдік, сол алаяқтарға қанша қызмет еттім, бәрі босқа!  \n15683                                                     Мен одан жақсылықтан өзге ештеңе көрген емеспін.  \n5911   — Достарым,— деді ол дауысын бәсең шығарып, өзімен өзі сөйлесіп тұрған кісі сияқтанып,— менің сө...  \n17979                                        Спектакль бұрын көргендеріме қарағанда жаман емес сияқты еді.  \n17522  Өте-мөте екі нәрсе айырықша назар аударады: біреуісі - сөре үстінде тұрған, қабысқан кішкене сам...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Source</th>\n      <th>Kazakh</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>28399</th>\n      <td>Мы более в нем не нуждаемся, мама.</td>\n      <td>− Ол енді бізге керек емес, апа.</td>\n    </tr>\n    <tr>\n      <th>12921</th>\n      <td>Через несколько дней Хосе Аркадио Буэндия подыскал дом для семейства коррехидора.</td>\n      <td>Бірнеше күн өткен соң, Хосе Аркадио Буэндиа коррехидордың отбасына үй тауып берді.</td>\n    </tr>\n    <tr>\n      <th>7802</th>\n      <td>Человек долго смотрел на Джоуда.</td>\n      <td>Oл адам Джoудқа ұзақ қарады.</td>\n    </tr>\n    <tr>\n      <th>4204</th>\n      <td>Легко себе представить, что странные повадки Динго не раз служили темой бесед, которые вели на к...</td>\n      <td>Дингоның адам таңқаларлық қылығы капитан Гульдің, миссис Уэлдонның және Диктің кеме кормосындағы...</td>\n    </tr>\n    <tr>\n      <th>33010</th>\n      <td>— Все исправно, — сказал англичанин.</td>\n      <td>— Бәз бабында бәрі, — деді ағылшын.</td>\n    </tr>\n    <tr>\n      <th>21581</th>\n      <td>Сколько мы плыли по реке, сколько делали для этих мошенников, и все зря!</td>\n      <td>Біз өзенмен қанша жол жүрдік, сол алаяқтарға қанша қызмет еттім, бәрі босқа!</td>\n    </tr>\n    <tr>\n      <th>15683</th>\n      <td>Я от него ничего не видела, кроме добра...</td>\n      <td>Мен одан жақсылықтан өзге ештеңе көрген емеспін.</td>\n    </tr>\n    <tr>\n      <th>5911</th>\n      <td>— Друзья мои, — сказал он вполголоса, как будто разговаривая сам с собой, — слушайте меня.</td>\n      <td>— Достарым,— деді ол дауысын бәсең шығарып, өзімен өзі сөйлесіп тұрған кісі сияқтанып,— менің сө...</td>\n    </tr>\n    <tr>\n      <th>17979</th>\n      <td>Спектакль был не такой дрянной, как те, что я раньше видел.</td>\n      <td>Спектакль бұрын көргендеріме қарағанда жаман емес сияқты еді.</td>\n    </tr>\n    <tr>\n      <th>17522</th>\n      <td>Две вещи здесь как-то странно останавливали внимание: небольшой погнутый самовар, стоявший на по...</td>\n      <td>Өте-мөте екі нәрсе айырықша назар аударады: біреуісі - сөре үстінде тұрған, қабысқан кішкене сам...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"trans_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T20:09:18.600900Z","iopub.execute_input":"2024-06-01T20:09:18.601268Z","iopub.status.idle":"2024-06-01T20:09:18.617473Z","shell.execute_reply.started":"2024-06-01T20:09:18.601238Z","shell.execute_reply":"2024-06-01T20:09:18.616541Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Source    0\nKazakh    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# this code is adapted from  the Stopes repo of the NLLB team\n# https://github.com/facebookresearch/stopes/blob/main/stopes/pipelines/monolingual/monolingual_line_processor.py#L214\n\nimport re\nimport sys\nimport typing as tp\nimport unicodedata\nfrom sacremoses import MosesPunctNormalizer\n\n\nmpn = MosesPunctNormalizer(lang=\"en\")\nmpn.substitutions = [\n    (re.compile(r), sub) for r, sub in mpn.substitutions\n]\n\n\ndef get_non_printing_char_replacer(replace_by: str = \" \") -> tp.Callable[[str], str]:\n    non_printable_map = {\n        ord(c): replace_by\n        for c in (chr(i) for i in range(sys.maxunicode + 1))\n        # same as \\p{C} in perl\n        # see https://www.unicode.org/reports/tr44/#General_Category_Values\n        if unicodedata.category(c) in {\"C\", \"Cc\", \"Cf\", \"Cs\", \"Co\", \"Cn\"}\n    }\n\n    def replace_non_printing_char(line) -> str:\n        return line.translate(non_printable_map)\n\n    return replace_non_printing_char\n\nreplace_nonprint = get_non_printing_char_replacer(\" \")\n\ndef preproc(text):\n    clean = mpn.normalize(text)\n    clean = replace_nonprint(clean)\n    # replace 𝓕𝔯𝔞𝔫𝔠𝔢𝔰𝔠𝔞 by Francesca\n    clean = unicodedata.normalize(\"NFKC\", clean)\n    return clean","metadata":{"execution":{"iopub.status.busy":"2024-06-01T20:09:19.180876Z","iopub.execute_input":"2024-06-01T20:09:19.181493Z","iopub.status.idle":"2024-06-01T20:09:20.446626Z","shell.execute_reply.started":"2024-06-01T20:09:19.181462Z","shell.execute_reply":"2024-06-01T20:09:20.445786Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Apply the preprocessing function to each column\ntrans_df['Kazakh'] = trans_df['Kazakh'].apply(preproc)\ntrans_df['Source'] = trans_df['Source'].apply(preproc)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T20:09:20.448229Z","iopub.execute_input":"2024-06-01T20:09:20.448518Z","iopub.status.idle":"2024-06-01T20:09:29.410573Z","shell.execute_reply.started":"2024-06-01T20:09:20.448494Z","shell.execute_reply":"2024-06-01T20:09:29.409744Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# dataset splitting into test, train, dev sets\ntest_size = 300\ndev_size = 300\n\n# First, create the training set and a remaining set (test + dev)\ntrain_df, remaining_df = train_test_split(trans_df, test_size=test_size + dev_size, random_state=42)\n\n# Split the remaining set into test and dev\ntest_df, dev_df = train_test_split(remaining_df, test_size=test_size, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-01T20:09:29.412146Z","iopub.execute_input":"2024-06-01T20:09:29.412495Z","iopub.status.idle":"2024-06-01T20:09:29.956030Z","shell.execute_reply.started":"2024-06-01T20:09:29.412462Z","shell.execute_reply":"2024-06-01T20:09:29.955252Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)\nprint(dev_df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T20:09:29.957790Z","iopub.execute_input":"2024-06-01T20:09:29.958104Z","iopub.status.idle":"2024-06-01T20:09:29.963089Z","shell.execute_reply.started":"2024-06-01T20:09:29.958075Z","shell.execute_reply":"2024-06-01T20:09:29.962233Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"(32091, 2)\n(300, 2)\n(300, 2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Preparing the training loop","metadata":{}},{"cell_type":"code","source":"import gc\nimport random\nimport numpy as np\nimport torch\nfrom tqdm.auto import tqdm, trange\nfrom transformers.optimization import Adafactor\nfrom transformers import get_constant_schedule_with_warmup\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TranslationPipeline\n\n\ndef cleanup():\n    \"\"\"Try to free GPU memory\"\"\"\n    gc.collect()\n    torch.cuda.empty_cache()\n\ncleanup()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T20:09:29.964112Z","iopub.execute_input":"2024-06-01T20:09:29.964370Z","iopub.status.idle":"2024-06-01T20:09:46.929630Z","shell.execute_reply.started":"2024-06-01T20:09:29.964347Z","shell.execute_reply":"2024-06-01T20:09:46.928748Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"2024-06-01 20:09:35.899846: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-01 20:09:35.899954: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-01 20:09:36.038901: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the tokenizer and model\nmodel_name = 'issai/tilmash'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T20:09:46.930751Z","iopub.execute_input":"2024-06-01T20:09:46.931310Z","iopub.status.idle":"2024-06-01T20:10:20.108559Z","shell.execute_reply.started":"2024-06-01T20:09:46.931272Z","shell.execute_reply":"2024-06-01T20:10:20.107530Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/544 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9ef0ee4d7f440949be7e1ebfc11e6e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c69e9a50c334491b8c0c6b417fea72f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"304c15c5d9e84b6fbd96020912d262c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/853 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbd2374681eb403d9c728c934885921c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/5.49G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a1d5c8fa76f40b6b6e1f64b5360d196"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"affa8a25f91447168a4db972ac35646b"}},"metadata":{}}]},{"cell_type":"code","source":"model.cuda()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T20:10:20.110145Z","iopub.execute_input":"2024-06-01T20:10:20.110443Z","iopub.status.idle":"2024-06-01T20:10:21.807905Z","shell.execute_reply.started":"2024-06-01T20:10:20.110417Z","shell.execute_reply":"2024-06-01T20:10:21.807015Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"M2M100ForConditionalGeneration(\n  (model): M2M100Model(\n    (shared): M2M100ScaledWordEmbedding(256206, 1024, padding_idx=1)\n    (encoder): M2M100Encoder(\n      (embed_tokens): M2M100ScaledWordEmbedding(256206, 1024, padding_idx=1)\n      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n      (layers): ModuleList(\n        (0-23): 24 x M2M100EncoderLayer(\n          (self_attn): M2M100Attention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): ReLU()\n          (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n          (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): M2M100Decoder(\n      (embed_tokens): M2M100ScaledWordEmbedding(256206, 1024, padding_idx=1)\n      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n      (layers): ModuleList(\n        (0-23): 24 x M2M100DecoderLayer(\n          (self_attn): M2M100Attention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): ReLU()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): M2M100Attention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n          (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=1024, out_features=256206, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = Adafactor(\n    [p for p in model.parameters() if p.requires_grad],\n    scale_parameter=False,\n    relative_step=False,\n    lr=1e-4,\n    clip_threshold=1.0,\n    weight_decay=1e-3,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T20:10:21.809120Z","iopub.execute_input":"2024-06-01T20:10:21.809450Z","iopub.status.idle":"2024-06-01T20:10:24.736687Z","shell.execute_reply.started":"2024-06-01T20:10:21.809419Z","shell.execute_reply":"2024-06-01T20:10:24.735430Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"batch_size = 8  # 32 already doesn't fit well to 15GB of GPU memory\nmax_length = 128\nwarmup_steps = 1_000\ntraining_steps = 57000","metadata":{"execution":{"iopub.status.busy":"2024-06-01T20:10:24.739811Z","iopub.execute_input":"2024-06-01T20:10:24.740829Z","iopub.status.idle":"2024-06-01T20:10:24.830776Z","shell.execute_reply.started":"2024-06-01T20:10:24.740780Z","shell.execute_reply":"2024-06-01T20:10:24.829576Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"losses = []\nscheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T20:10:24.832208Z","iopub.execute_input":"2024-06-01T20:10:24.832589Z","iopub.status.idle":"2024-06-01T20:10:24.889699Z","shell.execute_reply.started":"2024-06-01T20:10:24.832552Z","shell.execute_reply":"2024-06-01T20:10:24.888575Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"LANGS = [('Source', 'rus_Cyrl'), ('Kazakh', 'kaz_Cyrl')]\n\ndef get_batch_pairs(batch_size, data=train_df):\n    (l1, long1), (l2, long2) = random.sample(LANGS, 2)\n    xx, yy = [], []\n    for _ in range(batch_size):\n        item = data.iloc[random.randint(0, len(data)-1)]\n        xx.append(preproc(item[l1]))\n        yy.append(preproc(item[l2]))\n    return xx, yy, long1, long2\n\nprint(get_batch_pairs(1))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-01T20:10:31.966848Z","iopub.execute_input":"2024-06-01T20:10:31.967578Z","iopub.status.idle":"2024-06-01T20:10:31.975366Z","shell.execute_reply.started":"2024-06-01T20:10:31.967543Z","shell.execute_reply":"2024-06-01T20:10:31.974477Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"(['Күн асқан сайын жасыл желегі қоюланып келе жатқан жөке ағашы мен сары тал терезенің сыртынан көктем иісін себездеп, майда самал оны подвалға кіргізді.'], ['С каждым днем все сильнее зеленеющие липы и ветла за окном источали весенний запах, и начинающийся ветерок заносил его в подвал.'], 'kaz_Cyrl', 'rus_Cyrl')\n","output_type":"stream"}]},{"cell_type":"code","source":"model.train()\nx, y, loss = None, None, None\ncleanup()\n\ntq = trange(len(losses), training_steps)\nfor i in tq:\n    xx, yy, lang1, lang2 = get_batch_pairs(batch_size)\n    try:\n        tokenizer.src_lang = lang1\n        x = tokenizer(xx, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n        tokenizer.src_lang = lang2\n        y = tokenizer(yy, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(model.device)\n        y.input_ids[y.input_ids == tokenizer.pad_token_id] = -100\n\n        loss = model(**x, labels=y.input_ids).loss\n        loss.backward()\n        losses.append(loss.item())\n\n        optimizer.step()\n        optimizer.zero_grad(set_to_none=True)\n        scheduler.step()\n\n    except RuntimeError as e:\n        optimizer.zero_grad(set_to_none=True)\n        x, y, loss = None, None, None\n        cleanup()\n        print('error', max(len(s) for s in xx + yy), e)\n        continue\n\n    if i % 1000 == 0:\n        print(i, np.mean(losses[-1000:]))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-01T20:10:39.810020Z","iopub.execute_input":"2024-06-01T20:10:39.810714Z","iopub.status.idle":"2024-06-01T20:22:14.054421Z","shell.execute_reply.started":"2024-06-01T20:10:39.810667Z","shell.execute_reply":"2024-06-01T20:22:14.053010Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/57000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dc59d5216d84ef7b5f67f42fc5c3ab4"}},"metadata":{}},{"name":"stdout","text":"0 1.6621999740600586\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m y\u001b[38;5;241m.\u001b[39minput_ids[y\u001b[38;5;241m.\u001b[39minput_ids \u001b[38;5;241m==\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mx, labels\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39minput_ids)\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"savedModelPath = 'tilmash_fine_tuned'\nmodel.save_pretrained(savedModelPath)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T20:22:58.360207Z","iopub.execute_input":"2024-06-01T20:22:58.360576Z","iopub.status.idle":"2024-06-01T20:23:13.756906Z","shell.execute_reply.started":"2024-06-01T20:22:58.360549Z","shell.execute_reply":"2024-06-01T20:23:13.756079Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 200}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}